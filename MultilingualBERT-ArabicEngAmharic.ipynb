{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual BERT Approach\n",
    "\n",
    "Train on English and then Arabic and then Amharic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for GPU presence\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>áŠ áˆµá‰€á‹µáˆœ áŒ¥á‹«á‰„á‹¬ á‰ áŒ¨á‹‹áŠá‰µ á‰ á‹áˆµáŒ¥ áˆ˜áˆµáˆ˜áˆ­ áŠ¥áŠ•á‹²á‹°áˆ­áˆµá‹ áŠ á‹µáˆ­áŒŒ áá‰µáˆ…áŠ• áˆˆ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>áŠ¥áŠá‹šáˆ…áŠ• á‹ˆáˆ³áŠ áŒ‰á‹³á‹®á‰½áŠ• á‹¨áˆšá‹«áˆµáˆá…áˆ áŠ áŠ«áˆ áŠ¥áŠ•á‹²á‰‹á‰‹áˆáŠ“ áŠ­á‰µá‰µáˆ áŠ¥áŠ•á‹²á‹°áˆ¨...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>á‹¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‰ áŠ áŠ¥áˆáˆ® áŠ­áŠ•á‰ á‹«áˆá‰ áˆ¨áˆ¨á‰ á‰µ áŒ¥á‰ á‰¥áŠ“ ááˆáˆµááŠ“ á‹«áˆáŠ¨áˆá‰°á‹ á‹¨...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>áŠ¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‹¨áˆ€áŒˆáˆªá‰± á‹˜áˆ­áˆ á‰¥á‹™ áŠ¥á‹á‰€á‰µ áˆ˜áŠ•áŒ­á‰¶ á‹¨áˆáˆ‹á‰ á‰µáŠ¨áˆ™áˆ‹á‰±áˆ á‰ áˆ˜áˆ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>á‹›áˆ¬ á‰ á‹¨á‰µáŠ›á‹áˆ áˆ˜áˆˆáŠªá‹« á‹­áˆáŠ• áˆ˜áˆ˜á‹˜áŠ› áŠ¢á‰µá‹®áŒµá‹«á‹ŠáŠá‰µ á‹¨áˆšáŠ•á€á‰£áˆ¨á‰€á‹ á‰ áŠ áˆ›áˆ«...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29995</td>\n",
       "      <td>á‰ áŠ áˆ‰ á‹¨áˆáˆ‰áˆ áŠ¢á‰µá‹®áŒµá‹«á‹Š áˆµáˆ‹áˆáˆ†áŠ á‰ áŠ¦áˆ®áˆáŠ›á‹ á‰¢áˆˆá‹á‹°á‹µ áˆáŠ• áŠ áŒˆá‰£áŠ•</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29996</td>\n",
       "      <td>á‰°á‰£áˆ¨áŠ­ áŠ á‰¥á‰¹ áˆáˆ­ á‰€á‹³áŒ… áˆµáˆˆáˆ†áŠ•áˆ… áˆ˜áŒ‹áˆ¨áŒƒá‹ áˆ˜á‰€á‹°á‹µ áˆµáˆˆáŒ€áˆ˜áˆ¨</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>áŠ¥áˆµáŠ¨ áŠ áˆáŠ• áŠ áŠ•á‰° á‰¥á‰» áŠá‹ á‰    áˆ˜á…áˆ€á á‹«áˆá‰»áˆáŠ¨á‹  áŠ áŠ•á‰°áˆ á‰³áˆªáŠ­ áŠ¥áŠ•...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29998</td>\n",
       "      <td>áˆ…áŒˆá‹ˆáŒ¥á‰µ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ á‹¨á‰°áˆá‰€á‹° áˆ†áŠ– áˆ…á‹á‰¥áŠ• áŠ¥áŠ•á‹´á‰µ áˆ…áŒ áŠ áŠ­á‰¥...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>á‹°áŠá‹™ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ áˆ…áŒˆáˆ˜áŠ•áŒáˆµá‰µ áˆ³á‹­áˆ»áˆ»áˆ á‰ áˆ…áŒ á‹¨á‰°á‹ˆáˆ°áŠá‹‰áŠ• á‹¨...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a\n",
       "0          0  áŠ áˆµá‰€á‹µáˆœ áŒ¥á‹«á‰„á‹¬ á‰ áŒ¨á‹‹áŠá‰µ á‰ á‹áˆµáŒ¥ áˆ˜áˆµáˆ˜áˆ­ áŠ¥áŠ•á‹²á‹°áˆ­áˆµá‹ áŠ á‹µáˆ­áŒŒ áá‰µáˆ…áŠ• áˆˆ...       NOT\n",
       "1          1  áŠ¥áŠá‹šáˆ…áŠ• á‹ˆáˆ³áŠ áŒ‰á‹³á‹®á‰½áŠ• á‹¨áˆšá‹«áˆµáˆá…áˆ áŠ áŠ«áˆ áŠ¥áŠ•á‹²á‰‹á‰‹áˆáŠ“ áŠ­á‰µá‰µáˆ áŠ¥áŠ•á‹²á‹°áˆ¨...       NOT\n",
       "2          2  á‹¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‰ áŠ áŠ¥áˆáˆ® áŠ­áŠ•á‰ á‹«áˆá‰ áˆ¨áˆ¨á‰ á‰µ áŒ¥á‰ á‰¥áŠ“ ááˆáˆµááŠ“ á‹«áˆáŠ¨áˆá‰°á‹ á‹¨...       NOT\n",
       "3          3  áŠ¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‹¨áˆ€áŒˆáˆªá‰± á‹˜áˆ­áˆ á‰¥á‹™ áŠ¥á‹á‰€á‰µ áˆ˜áŠ•áŒ­á‰¶ á‹¨áˆáˆ‹á‰ á‰µáŠ¨áˆ™áˆ‹á‰±áˆ á‰ áˆ˜áˆ...       NOT\n",
       "4          4  á‹›áˆ¬ á‰ á‹¨á‰µáŠ›á‹áˆ áˆ˜áˆˆáŠªá‹« á‹­áˆáŠ• áˆ˜áˆ˜á‹˜áŠ› áŠ¢á‰µá‹®áŒµá‹«á‹ŠáŠá‰µ á‹¨áˆšáŠ•á€á‰£áˆ¨á‰€á‹ á‰ áŠ áˆ›áˆ«...       OFF\n",
       "...      ...                                                ...       ...\n",
       "29995  29995         á‰ áŠ áˆ‰ á‹¨áˆáˆ‰áˆ áŠ¢á‰µá‹®áŒµá‹«á‹Š áˆµáˆ‹áˆáˆ†áŠ á‰ áŠ¦áˆ®áˆáŠ›á‹ á‰¢áˆˆá‹á‹°á‹µ áˆáŠ• áŠ áŒˆá‰£áŠ•       OFF\n",
       "29996  29996             á‰°á‰£áˆ¨áŠ­ áŠ á‰¥á‰¹ áˆáˆ­ á‰€á‹³áŒ… áˆµáˆˆáˆ†áŠ•áˆ… áˆ˜áŒ‹áˆ¨áŒƒá‹ áˆ˜á‰€á‹°á‹µ áˆµáˆˆáŒ€áˆ˜áˆ¨       NOT\n",
       "29997  29997  áŠ¥áˆµáŠ¨ áŠ áˆáŠ• áŠ áŠ•á‰° á‰¥á‰» áŠá‹ á‰    áˆ˜á…áˆ€á á‹«áˆá‰»áˆáŠ¨á‹  áŠ áŠ•á‰°áˆ á‰³áˆªáŠ­ áŠ¥áŠ•...       NOT\n",
       "29998  29998  áˆ…áŒˆá‹ˆáŒ¥á‰µ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ á‹¨á‰°áˆá‰€á‹° áˆ†áŠ– áˆ…á‹á‰¥áŠ• áŠ¥áŠ•á‹´á‰µ áˆ…áŒ áŠ áŠ­á‰¥...       OFF\n",
       "29999  29999  á‹°áŠá‹™ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ áˆ…áŒˆáˆ˜áŠ•áŒáˆµá‰µ áˆ³á‹­áˆ»áˆ»áˆ á‰ áˆ…áŒ á‹¨á‰°á‹ˆáˆ°áŠá‹‰áŠ• á‹¨...       OFF\n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amharic_data = pd.read_csv('data/amharic/amharic.csv')\n",
    "amharic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>áŠ áˆµá‰€á‹µáˆœ áŒ¥á‹«á‰„á‹¬ á‰ áŒ¨á‹‹áŠá‰µ á‰ á‹áˆµáŒ¥ áˆ˜áˆµáˆ˜áˆ­ áŠ¥áŠ•á‹²á‹°áˆ­áˆµá‹ áŠ á‹µáˆ­áŒŒ áá‰µáˆ…áŠ• áˆˆ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>áŠ¥áŠá‹šáˆ…áŠ• á‹ˆáˆ³áŠ áŒ‰á‹³á‹®á‰½áŠ• á‹¨áˆšá‹«áˆµáˆá…áˆ áŠ áŠ«áˆ áŠ¥áŠ•á‹²á‰‹á‰‹áˆáŠ“ áŠ­á‰µá‰µáˆ áŠ¥áŠ•á‹²á‹°áˆ¨...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>á‹¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‰ áŠ áŠ¥áˆáˆ® áŠ­áŠ•á‰ á‹«áˆá‰ áˆ¨áˆ¨á‰ á‰µ áŒ¥á‰ á‰¥áŠ“ ááˆáˆµááŠ“ á‹«áˆáŠ¨áˆá‰°á‹ á‹¨...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>áŠ¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‹¨áˆ€áŒˆáˆªá‰± á‹˜áˆ­áˆ á‰¥á‹™ áŠ¥á‹á‰€á‰µ áˆ˜áŠ•áŒ­á‰¶ á‹¨áˆáˆ‹á‰ á‰µáŠ¨áˆ™áˆ‹á‰±áˆ á‰ áˆ˜áˆ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>á‹›áˆ¬ á‰ á‹¨á‰µáŠ›á‹áˆ áˆ˜áˆˆáŠªá‹« á‹­áˆáŠ• áˆ˜áˆ˜á‹˜áŠ› áŠ¢á‰µá‹®áŒµá‹«á‹ŠáŠá‰µ á‹¨áˆšáŠ•á€á‰£áˆ¨á‰€á‹ á‰ áŠ áˆ›áˆ«...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29995</td>\n",
       "      <td>á‰ áŠ áˆ‰ á‹¨áˆáˆ‰áˆ áŠ¢á‰µá‹®áŒµá‹«á‹Š áˆµáˆ‹áˆáˆ†áŠ á‰ áŠ¦áˆ®áˆáŠ›á‹ á‰¢áˆˆá‹á‹°á‹µ áˆáŠ• áŠ áŒˆá‰£áŠ•</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29996</td>\n",
       "      <td>á‰°á‰£áˆ¨áŠ­ áŠ á‰¥á‰¹ áˆáˆ­ á‰€á‹³áŒ… áˆµáˆˆáˆ†áŠ•áˆ… áˆ˜áŒ‹áˆ¨áŒƒá‹ áˆ˜á‰€á‹°á‹µ áˆµáˆˆáŒ€áˆ˜áˆ¨</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>áŠ¥áˆµáŠ¨ áŠ áˆáŠ• áŠ áŠ•á‰° á‰¥á‰» áŠá‹ á‰    áˆ˜á…áˆ€á á‹«áˆá‰»áˆáŠ¨á‹  áŠ áŠ•á‰°áˆ á‰³áˆªáŠ­ áŠ¥áŠ•...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29998</td>\n",
       "      <td>áˆ…áŒˆá‹ˆáŒ¥á‰µ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ á‹¨á‰°áˆá‰€á‹° áˆ†áŠ– áˆ…á‹á‰¥áŠ• áŠ¥áŠ•á‹´á‰µ áˆ…áŒ áŠ áŠ­á‰¥...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>á‹°áŠá‹™ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ áˆ…áŒˆáˆ˜áŠ•áŒáˆµá‰µ áˆ³á‹­áˆ»áˆ»áˆ á‰ áˆ…áŒ á‹¨á‰°á‹ˆáˆ°áŠá‹‰áŠ• á‹¨...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0          0  áŠ áˆµá‰€á‹µáˆœ áŒ¥á‹«á‰„á‹¬ á‰ áŒ¨á‹‹áŠá‰µ á‰ á‹áˆµáŒ¥ áˆ˜áˆµáˆ˜áˆ­ áŠ¥áŠ•á‹²á‹°áˆ­áˆµá‹ áŠ á‹µáˆ­áŒŒ áá‰µáˆ…áŠ• áˆˆ...       NOT   \n",
       "1          1  áŠ¥áŠá‹šáˆ…áŠ• á‹ˆáˆ³áŠ áŒ‰á‹³á‹®á‰½áŠ• á‹¨áˆšá‹«áˆµáˆá…áˆ áŠ áŠ«áˆ áŠ¥áŠ•á‹²á‰‹á‰‹áˆáŠ“ áŠ­á‰µá‰µáˆ áŠ¥áŠ•á‹²á‹°áˆ¨...       NOT   \n",
       "2          2  á‹¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‰ áŠ áŠ¥áˆáˆ® áŠ­áŠ•á‰ á‹«áˆá‰ áˆ¨áˆ¨á‰ á‰µ áŒ¥á‰ á‰¥áŠ“ ááˆáˆµááŠ“ á‹«áˆáŠ¨áˆá‰°á‹ á‹¨...       NOT   \n",
       "3          3  áŠ¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‹¨áˆ€áŒˆáˆªá‰± á‹˜áˆ­áˆ á‰¥á‹™ áŠ¥á‹á‰€á‰µ áˆ˜áŠ•áŒ­á‰¶ á‹¨áˆáˆ‹á‰ á‰µáŠ¨áˆ™áˆ‹á‰±áˆ á‰ áˆ˜áˆ...       NOT   \n",
       "4          4  á‹›áˆ¬ á‰ á‹¨á‰µáŠ›á‹áˆ áˆ˜áˆˆáŠªá‹« á‹­áˆáŠ• áˆ˜áˆ˜á‹˜áŠ› áŠ¢á‰µá‹®áŒµá‹«á‹ŠáŠá‰µ á‹¨áˆšáŠ•á€á‰£áˆ¨á‰€á‹ á‰ áŠ áˆ›áˆ«...       OFF   \n",
       "...      ...                                                ...       ...   \n",
       "29995  29995         á‰ áŠ áˆ‰ á‹¨áˆáˆ‰áˆ áŠ¢á‰µá‹®áŒµá‹«á‹Š áˆµáˆ‹áˆáˆ†áŠ á‰ áŠ¦áˆ®áˆáŠ›á‹ á‰¢áˆˆá‹á‹°á‹µ áˆáŠ• áŠ áŒˆá‰£áŠ•       OFF   \n",
       "29996  29996             á‰°á‰£áˆ¨áŠ­ áŠ á‰¥á‰¹ áˆáˆ­ á‰€á‹³áŒ… áˆµáˆˆáˆ†áŠ•áˆ… áˆ˜áŒ‹áˆ¨áŒƒá‹ áˆ˜á‰€á‹°á‹µ áˆµáˆˆáŒ€áˆ˜áˆ¨       NOT   \n",
       "29997  29997  áŠ¥áˆµáŠ¨ áŠ áˆáŠ• áŠ áŠ•á‰° á‰¥á‰» áŠá‹ á‰    áˆ˜á…áˆ€á á‹«áˆá‰»áˆáŠ¨á‹  áŠ áŠ•á‰°áˆ á‰³áˆªáŠ­ áŠ¥áŠ•...       NOT   \n",
       "29998  29998  áˆ…áŒˆá‹ˆáŒ¥á‰µ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ á‹¨á‰°áˆá‰€á‹° áˆ†áŠ– áˆ…á‹á‰¥áŠ• áŠ¥áŠ•á‹´á‰µ áˆ…áŒ áŠ áŠ­á‰¥...       OFF   \n",
       "29999  29999  á‹°áŠá‹™ áŒ á‰…áˆ‹á‹­ áˆšáŠ•áˆµá‰µáˆ­ á…á‰¤á‰µ áˆ…áŒˆáˆ˜áŠ•áŒáˆµá‰µ áˆ³á‹­áˆ»áˆ»áˆ á‰ áˆ…áŒ á‹¨á‰°á‹ˆáˆ°áŠá‹‰áŠ• á‹¨...       OFF   \n",
       "\n",
       "       label  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        1.0  \n",
       "...      ...  \n",
       "29995    1.0  \n",
       "29996    0.0  \n",
       "29997    0.0  \n",
       "29998    1.0  \n",
       "29999    1.0  \n",
       "\n",
       "[30000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating new column with 0/1\n",
    "#df.loc[(df[\"Q35\"]==\"N/A (no satisfaction surveys conducted)\"),\"Q37_F\"]=\n",
    "amharic_data[\"label\"] = np.nan\n",
    "amharic_data.loc[(amharic_data[\"subtask_a\"] == \"OFF\"), \"label\"] = 1\n",
    "amharic_data.loc[(amharic_data[\"subtask_a\"] == \"NOT\"), \"label\"] = 0\n",
    "amharic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13236  67210  Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...       NOT   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13235       TIN       IND  \n",
       "13236       NaN       NaN  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "13239       NaN       NaN  \n",
       "\n",
       "[13240 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english = pd.read_csv(\"data/olid/olid-training-v1.0.tsv\", sep =\"\\t\")\n",
    "english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13236  67210  Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...       NOT   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  label  \n",
       "0           UNT       NaN    1.0  \n",
       "1           TIN       IND    1.0  \n",
       "2           NaN       NaN    0.0  \n",
       "3           UNT       NaN    1.0  \n",
       "4           NaN       NaN    0.0  \n",
       "...         ...       ...    ...  \n",
       "13235       TIN       IND    1.0  \n",
       "13236       NaN       NaN    0.0  \n",
       "13237       TIN       OTH    1.0  \n",
       "13238       UNT       NaN    1.0  \n",
       "13239       NaN       NaN    0.0  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english[\"label\"] = np.nan\n",
    "english.loc[(english[\"subtask_a\"] == \"OFF\"), \"label\"] = 1\n",
    "english.loc[(english[\"subtask_a\"] == \"NOT\"), \"label\"] = 0\n",
    "english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø£Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø£Ù‡Ù… ÙŠØ§ Ø¥Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø£ÙƒÙˆÙ† ğŸ¼</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>7996</td>\n",
       "      <td>RT @USER: Ø§Ù†ØªÙˆ Ø¨ØªÙˆØ²Ø¹ÙˆØ§ Ø²ÙŠØª ÙˆØ³ÙƒØ± ÙØ¹Ù„Ø§ ÙŠØ§ Ø¹Ø¨Ø§Ø³ØŸ&lt;...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>7997</td>\n",
       "      <td>RT @USER: ÙƒØ¯Ø§ ÙŠØ§ Ø¹Ù…Ø± Ù…ØªØ²Ø¹Ù„Ù‡Ø§Ø´ ÙŠØ§ Ø­Ø¨ÙŠØ¨ÙŠ ğŸ˜‚ URL</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>7998</td>\n",
       "      <td>Ù‡Ø¯Ø§ Ø³ÙƒÙ† Ø§Ø·ÙØ§Ù„ Ø§Ù…Ø§Ø±ØªÙŠÙ† Ù…Ù† Ø´Ø§Ø±Ù‚Ø© Ø·Ø§Ù„Ø¨ÙŠÙ† ÙØ²Ø¹ØªÙƒÙ… ÙŠ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>7999</td>\n",
       "      <td>RT @USER: ÙˆÙ…Ø¯Ù†ÙŠ Ø¨Ù…Ø¯Ø¯ Ù…Ù† Ù‚ÙˆØªÙƒ Ø£ÙˆØ§Ø¬Ù‡ Ø¨Ù‡ Ø¶Ø¹ÙÙŠ.. Ùˆ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>8000</td>\n",
       "      <td>ÙŠØ§ Ø³Ù„Ø§Ø§Ø§Ø§Ø§Ù… ÙŠØ§ ÙŠÙˆ Ø®Ø§Ù„Ø¯ Ø§Ù†Øª ÙˆØ§Ù„Ø·Ø±Ø¨ Ø§Ù„Ø§ØµÙŠÙ„ URL</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7839 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet subtask_a\n",
       "0        1  Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...       NOT\n",
       "1        2            ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡       NOT\n",
       "2        3  RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø£Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...       OFF\n",
       "3        4  RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...       NOT\n",
       "4        5          ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø£Ù‡Ù… ÙŠØ§ Ø¥Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø£ÙƒÙˆÙ† ğŸ¼       NOT\n",
       "...    ...                                                ...       ...\n",
       "7834  7996  RT @USER: Ø§Ù†ØªÙˆ Ø¨ØªÙˆØ²Ø¹ÙˆØ§ Ø²ÙŠØª ÙˆØ³ÙƒØ± ÙØ¹Ù„Ø§ ÙŠØ§ Ø¹Ø¨Ø§Ø³ØŸ<...       NOT\n",
       "7835  7997       RT @USER: ÙƒØ¯Ø§ ÙŠØ§ Ø¹Ù…Ø± Ù…ØªØ²Ø¹Ù„Ù‡Ø§Ø´ ÙŠØ§ Ø­Ø¨ÙŠØ¨ÙŠ ğŸ˜‚ URL       NOT\n",
       "7836  7998  Ù‡Ø¯Ø§ Ø³ÙƒÙ† Ø§Ø·ÙØ§Ù„ Ø§Ù…Ø§Ø±ØªÙŠÙ† Ù…Ù† Ø´Ø§Ø±Ù‚Ø© Ø·Ø§Ù„Ø¨ÙŠÙ† ÙØ²Ø¹ØªÙƒÙ… ÙŠ...       NOT\n",
       "7837  7999  RT @USER: ÙˆÙ…Ø¯Ù†ÙŠ Ø¨Ù…Ø¯Ø¯ Ù…Ù† Ù‚ÙˆØªÙƒ Ø£ÙˆØ§Ø¬Ù‡ Ø¨Ù‡ Ø¶Ø¹ÙÙŠ.. Ùˆ...       NOT\n",
       "7838  8000       ÙŠØ§ Ø³Ù„Ø§Ø§Ø§Ø§Ø§Ù… ÙŠØ§ ÙŠÙˆ Ø®Ø§Ù„Ø¯ Ø§Ù†Øª ÙˆØ§Ù„Ø·Ø±Ø¨ Ø§Ù„Ø§ØµÙŠÙ„ URL       NOT\n",
       "\n",
       "[7839 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic = pd.read_csv(\"data/Arabic/train.tsv\", sep = \"\\t\")\n",
    "arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø£Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø£Ù‡Ù… ÙŠØ§ Ø¥Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø£ÙƒÙˆÙ† ğŸ¼</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>7996</td>\n",
       "      <td>RT @USER: Ø§Ù†ØªÙˆ Ø¨ØªÙˆØ²Ø¹ÙˆØ§ Ø²ÙŠØª ÙˆØ³ÙƒØ± ÙØ¹Ù„Ø§ ÙŠØ§ Ø¹Ø¨Ø§Ø³ØŸ&lt;...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>7997</td>\n",
       "      <td>RT @USER: ÙƒØ¯Ø§ ÙŠØ§ Ø¹Ù…Ø± Ù…ØªØ²Ø¹Ù„Ù‡Ø§Ø´ ÙŠØ§ Ø­Ø¨ÙŠØ¨ÙŠ ğŸ˜‚ URL</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>7998</td>\n",
       "      <td>Ù‡Ø¯Ø§ Ø³ÙƒÙ† Ø§Ø·ÙØ§Ù„ Ø§Ù…Ø§Ø±ØªÙŠÙ† Ù…Ù† Ø´Ø§Ø±Ù‚Ø© Ø·Ø§Ù„Ø¨ÙŠÙ† ÙØ²Ø¹ØªÙƒÙ… ÙŠ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>7999</td>\n",
       "      <td>RT @USER: ÙˆÙ…Ø¯Ù†ÙŠ Ø¨Ù…Ø¯Ø¯ Ù…Ù† Ù‚ÙˆØªÙƒ Ø£ÙˆØ§Ø¬Ù‡ Ø¨Ù‡ Ø¶Ø¹ÙÙŠ.. Ùˆ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>8000</td>\n",
       "      <td>ÙŠØ§ Ø³Ù„Ø§Ø§Ø§Ø§Ø§Ù… ÙŠØ§ ÙŠÙˆ Ø®Ø§Ù„Ø¯ Ø§Ù†Øª ÙˆØ§Ù„Ø·Ø±Ø¨ Ø§Ù„Ø§ØµÙŠÙ„ URL</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7839 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet subtask_a  label\n",
       "0        1  Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...       NOT    0.0\n",
       "1        2            ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡       NOT    0.0\n",
       "2        3  RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø£Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...       OFF    1.0\n",
       "3        4  RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...       NOT    0.0\n",
       "4        5          ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø£Ù‡Ù… ÙŠØ§ Ø¥Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø£ÙƒÙˆÙ† ğŸ¼       NOT    0.0\n",
       "...    ...                                                ...       ...    ...\n",
       "7834  7996  RT @USER: Ø§Ù†ØªÙˆ Ø¨ØªÙˆØ²Ø¹ÙˆØ§ Ø²ÙŠØª ÙˆØ³ÙƒØ± ÙØ¹Ù„Ø§ ÙŠØ§ Ø¹Ø¨Ø§Ø³ØŸ<...       NOT    0.0\n",
       "7835  7997       RT @USER: ÙƒØ¯Ø§ ÙŠØ§ Ø¹Ù…Ø± Ù…ØªØ²Ø¹Ù„Ù‡Ø§Ø´ ÙŠØ§ Ø­Ø¨ÙŠØ¨ÙŠ ğŸ˜‚ URL       NOT    0.0\n",
       "7836  7998  Ù‡Ø¯Ø§ Ø³ÙƒÙ† Ø§Ø·ÙØ§Ù„ Ø§Ù…Ø§Ø±ØªÙŠÙ† Ù…Ù† Ø´Ø§Ø±Ù‚Ø© Ø·Ø§Ù„Ø¨ÙŠÙ† ÙØ²Ø¹ØªÙƒÙ… ÙŠ...       NOT    0.0\n",
       "7837  7999  RT @USER: ÙˆÙ…Ø¯Ù†ÙŠ Ø¨Ù…Ø¯Ø¯ Ù…Ù† Ù‚ÙˆØªÙƒ Ø£ÙˆØ§Ø¬Ù‡ Ø¨Ù‡ Ø¶Ø¹ÙÙŠ.. Ùˆ...       NOT    0.0\n",
       "7838  8000       ÙŠØ§ Ø³Ù„Ø§Ø§Ø§Ø§Ø§Ù… ÙŠØ§ ÙŠÙˆ Ø®Ø§Ù„Ø¯ Ø§Ù†Øª ÙˆØ§Ù„Ø·Ø±Ø¨ Ø§Ù„Ø§ØµÙŠÙ„ URL       NOT    0.0\n",
       "\n",
       "[7839 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic[\"label\"] = np.nan\n",
    "arabic.loc[(arabic[\"subtask_a\"] == \"OFF\"), \"label\"] = 1\n",
    "arabic.loc[(arabic[\"subtask_a\"] == \"NOT\"), \"label\"] = 0\n",
    "arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 4)\n",
      "(1500, 4)\n",
      "(1500, 4)\n"
     ]
    }
   ],
   "source": [
    "#load our tuned Amharic dataset\n",
    "amharic_train, amharic_test = train_test_split(amharic_data, train_size=0.9)\n",
    "amharic_test, amharic_dev = train_test_split(amharic_test, train_size=0.5)\n",
    "print(amharic_train.shape)\n",
    "print(amharic_test.shape)\n",
    "print(amharic_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20950</th>\n",
       "      <td>20950</td>\n",
       "      <td>áŠ á‰µá‰€á‰£áŒ¥áˆ­ áˆ›áŠá‹«á‹á‰½ áˆ˜áŒ¥áŠá‹«á‰¹ áŠ¥á‹¨á‹°áˆ¨áˆ° áŠá‹á‹¨á‰µáŒáˆ«á‹­áŠ• áˆ…á‹á‰¥ áˆ˜áŒ¡á‰¥áˆ… áŠ¥á‹«áˆ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>28510</td>\n",
       "      <td>áˆµáˆˆ áˆ™áˆµáˆŠáˆ áˆ˜á‰¥á‰µ áˆ™áˆµáˆŠáˆ á‹­áŒ á‹­á‰… áŠ áŠ•á‰° áˆ™áˆµáˆŠáˆáŠ• á‹ˆáŠ­áˆˆáˆ… áˆ˜áŒ á‹¨á‰… áŠ á‰µá‰½áˆáˆ</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15669</th>\n",
       "      <td>15669</td>\n",
       "      <td>áˆˆáˆ± á‹¨á‰°áˆ˜áŠ˜áˆ€á‹ áˆá‰° áˆˆáŒ áˆ‹á‰± áŠ­á‰ áˆˆáˆšáˆ˜áŠáˆˆá‰µ á‹­áˆáŠ•</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15875</th>\n",
       "      <td>15875</td>\n",
       "      <td>áˆšáŠª á‰ áˆ˜áˆáŒ£á‰µáˆ… á‹°áˆµ á‰¥áˆáŠ“áˆ</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13655</th>\n",
       "      <td>13655</td>\n",
       "      <td>á‹°á‹°á‰¥</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>7776</td>\n",
       "      <td>áŒŒáŒ¡ á‹¨áˆšáˆ¨á‰£ áŠáŒˆáˆ­ áƒá áŠ á‰³á‰ áˆ³áŒ¨áŠ á‰ áŠ áŠ•á‹µ áŒŠá‹œ á‹¨á‹µáˆ«áˆ› á‹°áˆ¨áˆ² áŠ á‹°áˆ¨áŒˆáˆ… áŒ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>573</td>\n",
       "      <td>áŠ áˆáˆ‹áŠ­ áˆ†á‹­ áˆˆáŠ¢á‰µá‹®áŒµá‹« á‹¨áŒˆá‰£áˆ…áˆ‹á‰µáŠ• á‰ƒáˆ áŠ áˆµá‰³á‹áˆµ</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>646</td>\n",
       "      <td>á‹«áˆ›áˆ á‰ áŒ£áˆ á‰°á‹‹á‹¶ á‰°áŒ‹á‰¥á‰¶ á‰°á‹‹áˆá‹¶ á‹¨áŠ–áˆ¨ á‹« áá‰…áˆ­ á‹¨áˆ†áŠ áˆ…á‹á‰¥ áˆ²áŒˆá‹³á‹°áˆáŠ ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19360</th>\n",
       "      <td>19360</td>\n",
       "      <td>áŠ¥á‹šáˆ… áŒ‹áˆ­ á‹¨á‰°áŒ‹áˆ©áˆµ áˆ˜áŠ•áŒ«áŒ«á‰µ á‹¨áŠáŒˆáˆ¨áŠ áˆ˜áŒˆáŠ•áŒ áˆáŠ• á‹«á‹ˆáˆ©á‰³áˆ áŠ¥áŠ•áŒ‚ áˆˆáˆ˜áˆá€...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>2990</td>\n",
       "      <td>á‰‹áŠ•á‰‹ áˆ†á‹µ áŠ á‹­áˆáˆ‹</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "20950  20950  áŠ á‰µá‰€á‰£áŒ¥áˆ­ áˆ›áŠá‹«á‹á‰½ áˆ˜áŒ¥áŠá‹«á‰¹ áŠ¥á‹¨á‹°áˆ¨áˆ° áŠá‹á‹¨á‰µáŒáˆ«á‹­áŠ• áˆ…á‹á‰¥ áˆ˜áŒ¡á‰¥áˆ… áŠ¥á‹«áˆ...       NOT   \n",
       "28510  28510    áˆµáˆˆ áˆ™áˆµáˆŠáˆ áˆ˜á‰¥á‰µ áˆ™áˆµáˆŠáˆ á‹­áŒ á‹­á‰… áŠ áŠ•á‰° áˆ™áˆµáˆŠáˆáŠ• á‹ˆáŠ­áˆˆáˆ… áˆ˜áŒ á‹¨á‰… áŠ á‰µá‰½áˆáˆ       NOT   \n",
       "15669  15669                    áˆˆáˆ± á‹¨á‰°áˆ˜áŠ˜áˆ€á‹ áˆá‰° áˆˆáŒ áˆ‹á‰± áŠ­á‰ áˆˆáˆšáˆ˜áŠáˆˆá‰µ á‹­áˆáŠ•       OFF   \n",
       "15875  15875                                  áˆšáŠª á‰ áˆ˜áˆáŒ£á‰µáˆ… á‹°áˆµ á‰¥áˆáŠ“áˆ       NOT   \n",
       "13655  13655                                                á‹°á‹°á‰¥       OFF   \n",
       "...      ...                                                ...       ...   \n",
       "7776    7776  áŒŒáŒ¡ á‹¨áˆšáˆ¨á‰£ áŠáŒˆáˆ­ áƒá áŠ á‰³á‰ áˆ³áŒ¨áŠ á‰ áŠ áŠ•á‹µ áŒŠá‹œ á‹¨á‹µáˆ«áˆ› á‹°áˆ¨áˆ² áŠ á‹°áˆ¨áŒˆáˆ… áŒ...       OFF   \n",
       "573      573                    áŠ áˆáˆ‹áŠ­ áˆ†á‹­ áˆˆáŠ¢á‰µá‹®áŒµá‹« á‹¨áŒˆá‰£áˆ…áˆ‹á‰µáŠ• á‰ƒáˆ áŠ áˆµá‰³á‹áˆµ       NOT   \n",
       "646      646  á‹«áˆ›áˆ á‰ áŒ£áˆ á‰°á‹‹á‹¶ á‰°áŒ‹á‰¥á‰¶ á‰°á‹‹áˆá‹¶ á‹¨áŠ–áˆ¨ á‹« áá‰…áˆ­ á‹¨áˆ†áŠ áˆ…á‹á‰¥ áˆ²áŒˆá‹³á‹°áˆáŠ ...       NOT   \n",
       "19360  19360  áŠ¥á‹šáˆ… áŒ‹áˆ­ á‹¨á‰°áŒ‹áˆ©áˆµ áˆ˜áŠ•áŒ«áŒ«á‰µ á‹¨áŠáŒˆáˆ¨áŠ áˆ˜áŒˆáŠ•áŒ áˆáŠ• á‹«á‹ˆáˆ©á‰³áˆ áŠ¥áŠ•áŒ‚ áˆˆáˆ˜áˆá€...       OFF   \n",
       "2990    2990                                        á‰‹áŠ•á‰‹ áˆ†á‹µ áŠ á‹­áˆáˆ‹       NOT   \n",
       "\n",
       "       label  \n",
       "20950    0.0  \n",
       "28510    0.0  \n",
       "15669    1.0  \n",
       "15875    0.0  \n",
       "13655    1.0  \n",
       "...      ...  \n",
       "7776     1.0  \n",
       "573      0.0  \n",
       "646      0.0  \n",
       "19360    1.0  \n",
       "2990     0.0  \n",
       "\n",
       "[27000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amharic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length tweet is: 254\n",
      "min length tweet is: 1\n",
      "mean length tweet is: 18.026133333333334\n"
     ]
    }
   ],
   "source": [
    "#Find the maximum length tweet\n",
    "print(\"max length tweet is:\",np.max([len(x.split()) for x in amharic_data.tweet]))\n",
    "print(\"min length tweet is:\",np.min([len(x.split()) for x in amharic_data.tweet]))\n",
    "print(\"mean length tweet is:\",np.mean([len(x.split()) for x in amharic_data.tweet]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to run BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#NEED to import and load both of these\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  167356416 \n",
      "=================================================================\n",
      "Total params: 167,356,416\n",
      "Trainable params: 167,356,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_length = 100 #use to to a bit larger than the mean tweet length\n",
    "\n",
    "x_train = tokenizer([x for x in amharic_train.tweet], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_train = amharic_train.label\n",
    "\n",
    "eng_x_train = tokenizer([x for x in english.tweet], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "eng_y_train = english.label\n",
    "\n",
    "\n",
    "arabic_x_train = tokenizer([x for x in arabic.tweet], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "arabic_y_train = arabic.label\n",
    "\n",
    "\n",
    "x_dev = tokenizer([x for x in amharic_dev.tweet], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_dev = amharic_dev.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of positive examples:  0.5070370370370371\n"
     ]
    }
   ],
   "source": [
    "#Let's look at class imbalance\n",
    "print('ratio of positive examples: ', np.sum(y_train==1)/len(y_train))\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(27000, 100), dtype=int32, numpy=\n",
       "array([[101, 100, 100, ...,   0,   0,   0],\n",
       "       [101, 100, 100, ...,   0,   0,   0],\n",
       "       [101, 100, 100, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [101, 100, 100, ...,   0,   0,   0],\n",
       "       [101, 100, 100, ...,   0,   0,   0],\n",
       "       [101, 100, 100, ...,   0,   0,   0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(27000, 100), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(27000, 100), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From BERT_Fine_tuning Walkthrough Notebook/Session\n",
    "\n",
    "def create_classification_model(hidden_size = 200, \n",
    "                                train_layers = -1, \n",
    "                                optimizer=tf.keras.optimizers.Adam()):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Let's keep it simple and don't add dropout, layer norms, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                  'token_type_ids': token_type_ids,\n",
    "                  'attention_mask': attention_mask}\n",
    "\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "\n",
    "\n",
    "    bert_out = bert_model(bert_inputs) #same as x_tiny example above, always set ouput to model acting on input\n",
    "\n",
    "    \n",
    "    #getting the CLS token, could change to bert_out[1]\n",
    "    classification_token = tf.keras.layers.Lambda(lambda x: x[:,0,:], name='get_first_vector')(bert_out[0]) \n",
    "\n",
    "\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, name='hidden_layer')(classification_token)\n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], \n",
    "                                          outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=optimizer,\n",
    "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                            metrics='accuracy')\n",
    "\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "Creating models and changing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Fit on English and then Amharic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = create_classification_model()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1655/1655 [==============================] - 416s 246ms/step - loss: 0.7660 - accuracy: 0.6241 - val_loss: 0.6358 - val_accuracy: 0.6677\n",
      "Epoch 2/5\n",
      "1655/1655 [==============================] - 405s 245ms/step - loss: 0.6462 - accuracy: 0.6622 - val_loss: 0.6360 - val_accuracy: 0.6677\n",
      "Epoch 3/5\n",
      "1655/1655 [==============================] - 406s 245ms/step - loss: 0.6406 - accuracy: 0.6658 - val_loss: 0.6389 - val_accuracy: 0.6677\n",
      "Epoch 4/5\n",
      "1655/1655 [==============================] - 405s 245ms/step - loss: 0.6434 - accuracy: 0.6605 - val_loss: 0.6387 - val_accuracy: 0.6677\n",
      "Epoch 5/5\n",
      "1655/1655 [==============================] - 405s 245ms/step - loss: 0.6390 - accuracy: 0.6686 - val_loss: 0.6369 - val_accuracy: 0.6677\n",
      "Epoch 1/5\n",
      "3375/3375 [==============================] - 674s 200ms/step - loss: 0.6951 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5067\n",
      "Epoch 2/5\n",
      "3375/3375 [==============================] - 671s 199ms/step - loss: 0.6943 - accuracy: 0.5022 - val_loss: 0.6941 - val_accuracy: 0.4933\n",
      "Epoch 3/5\n",
      "3375/3375 [==============================] - 671s 199ms/step - loss: 0.6939 - accuracy: 0.5041 - val_loss: 0.6943 - val_accuracy: 0.4933\n",
      "Epoch 4/5\n",
      "3375/3375 [==============================] - 670s 199ms/step - loss: 0.6942 - accuracy: 0.5045 - val_loss: 0.6945 - val_accuracy: 0.5067\n",
      "Epoch 5/5\n",
      "3375/3375 [==============================] - 670s 199ms/step - loss: 0.6942 - accuracy: 0.5002 - val_loss: 0.6945 - val_accuracy: 0.4933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2bbc3b1700>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit on English\n",
    "classification_model.fit([eng_x_train.input_ids, eng_x_train.token_type_ids, eng_x_train.attention_mask],\n",
    "                         eng_y_train,\n",
    "                         validation_data=([eng_x_train.input_ids, eng_x_train.token_type_ids, eng_x_train.attention_mask],\n",
    "                         eng_y_train),\n",
    "                        epochs=5,\n",
    "                        batch_size=8)\n",
    "\n",
    "\n",
    "#Fit on Amharic train\n",
    "classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train,\n",
    "                         validation_data=([x_dev.input_ids, x_dev.token_type_ids, x_dev.attention_mask],\n",
    "                         y_dev),\n",
    "                        epochs=5,\n",
    "                        batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask]) \n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask_layer (InputLaye [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids_layer (InputLayer)    [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids_layer (InputLaye [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 167356416   attention_mask_layer[0][0]       \n",
      "                                                                 input_ids_layer[0][0]            \n",
      "                                                                 token_type_ids_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "get_first_vector (Lambda)       (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer (Dense)            (None, 200)          153800      get_first_vector[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "classification_layer (Dense)    (None, 1)            201         hidden_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 167,510,417\n",
      "Trainable params: 167,510,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([27000, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.token_type_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6932680010795593 / Train accuracy: 0.5084444284439087\n"
     ]
    }
   ],
   "source": [
    "score = classification_model.evaluate([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train, verbose=0)\n",
    "print(f'Train loss: {score[0]} / Train accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6944733262062073 / Test accuracy: 0.4933333396911621\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = classification_model.evaluate([x_dev.input_ids, x_dev.token_type_ids, x_dev.attention_mask],\n",
    "                         y_dev, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Following Model 2 from BERT Walkthrough notebook\n",
    "Updating learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3375/3375 [==============================] - 682s 200ms/step - loss: 0.7138 - accuracy: 0.5033 - val_loss: 0.7106 - val_accuracy: 0.4933\n",
      "Epoch 2/5\n",
      "3375/3375 [==============================] - 672s 199ms/step - loss: 0.6993 - accuracy: 0.5062 - val_loss: 0.6971 - val_accuracy: 0.4933\n",
      "Epoch 3/5\n",
      "3375/3375 [==============================] - 672s 199ms/step - loss: 0.6984 - accuracy: 0.4970 - val_loss: 0.6936 - val_accuracy: 0.4933\n",
      "Epoch 4/5\n",
      "3375/3375 [==============================] - 672s 199ms/step - loss: 0.6976 - accuracy: 0.4979 - val_loss: 0.6955 - val_accuracy: 0.4933\n",
      "Epoch 5/5\n",
      "3375/3375 [==============================] - 676s 200ms/step - loss: 0.6953 - accuracy: 0.5050 - val_loss: 0.6940 - val_accuracy: 0.5067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.47117275],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.47117275],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ],\n",
       "       [0.4711727 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do same thing as above but change learning rate in Adam below, need to get fresh bert model\n",
    "try:\n",
    "    del classification_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del bert_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "classification_model = create_classification_model(optimizer=tf.keras.optimizers.Adam(0.00005))\n",
    "\n",
    "classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train,\n",
    "                         validation_data=([x_dev.input_ids, x_dev.token_type_ids, x_dev.attention_mask],\n",
    "                         y_dev),\n",
    "                        epochs=5,\n",
    "                        batch_size=8)\n",
    "\n",
    "classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n",
    "                             batch_size=8, \n",
    "                             steps=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6957873106002808 / Train accuracy: 0.4915555417537689\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = classification_model.evaluate([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train, verbose=0)\n",
    "print(f'Train loss: {score[0]} / Train accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6977327466011047 / Test accuracy: 0.4959999918937683\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = classification_model.evaluate([x_dev.input_ids, x_dev.token_type_ids, x_dev.attention_mask],\n",
    "                         y_dev, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask_layer (InputLaye [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids_layer (InputLayer)    [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids_layer (InputLaye [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   attention_mask_layer[0][0]       \n",
      "                                                                 input_ids_layer[0][0]            \n",
      "                                                                 token_type_ids_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "get_first_vector (Lambda)       (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer (Dense)            (None, 200)          153800      get_first_vector[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "classification_layer (Dense)    (None, 1)            201         hidden_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 108,464,273\n",
      "Trainable params: 108,464,273\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8b12a87bde52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/BERT_multilingual_adam_v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/BERT_multilingual_v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "classification_model.save_model(\"models/BERT_multilingual_adam_v1\")\n",
    "tokenizer.save_pretrained(\"tokenizers/BERT_multilingual_v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
